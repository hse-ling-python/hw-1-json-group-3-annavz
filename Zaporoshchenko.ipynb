{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №1, Анна Запорощенко, БКЛ183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycodestyle in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: flake8 in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (3.7.8)\n",
      "Requirement already satisfied: pycodestyle_magic in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from flake8) (0.6.1)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from flake8) (2.1.1)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in c:\\users\\vadik\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages (from flake8) (0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pycodestyle flake8 pycodestyle_magic\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 1: Сколько твитов в наборе?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываю файл, читаю его построчно, затем преобразую каждый json в объект python и складываю в список twitter. Узнаю длину списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего твитов в наборе:  2556\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('hw_3_twitter.json', 'r', encoding='utf-8') as twits:\n",
    "    twits = twits.readlines()\n",
    "twitter = []\n",
    "for line in twits:\n",
    "    twitter.append(json.loads(line))\n",
    "numberoftwits = len(twitter)\n",
    "print('Всего твитов в наборе: ', numberoftwits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 2: Какой процент составляют удаленные записи?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебираю список twitter и с помощью .keys() вынимаю все ключи в список keys. Проверяю каждый первый член списка: если он является пометкой delete, добавляю + 1 к счетчику. Для будущей работы складываю все существующие твиты в отдельный список Вычисляю и вывожу процент удаленных твитов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент удаленных записей равен:  14.162754303599373 %\n"
     ]
    }
   ],
   "source": [
    "alld = 0\n",
    "existing = []\n",
    "for twit in twitter:\n",
    "    keys = list(twit.keys())\n",
    "    if keys[0] == 'delete':\n",
    "        alld += 1\n",
    "    else:\n",
    "        existing.append(twit)\n",
    "percentage = alld / numberoftwits * 100\n",
    "print('Процент удаленных записей равен: ', percentage, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 3: Какие самые популярные языки твитов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из каждого существующего твита достаю информацию о языке по ключу lang. С помощью Conter и most_common выясняю 10 самых частотных языков. Вывожу данные в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 наиболее часто используемых языков:\n",
      "Номер \t Язык \t Количество твитов\n",
      "1 \t en \t 719\n",
      "2 \t ja \t 438\n",
      "3 \t es \t 173\n",
      "4 \t ko \t 149\n",
      "5 \t th \t 123\n",
      "6 \t ar \t 119\n",
      "7 \t und \t 117\n",
      "8 \t in \t 71\n",
      "9 \t pt \t 69\n",
      "10 \t fr \t 35\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "languages = []\n",
    "for twit in existing:\n",
    "    language = twit['lang']\n",
    "    languages.append(language)\n",
    "toplang = Counter(languages).most_common(10)\n",
    "\n",
    "numb = 1\n",
    "print('Топ-10 наиболее часто используемых языков:')\n",
    "print('Номер', '\\t', 'Язык', '\\t', 'Количество твитов')\n",
    "for lang in toplang:\n",
    "    print(numb, '\\t', lang[0], '\\t', lang[1])\n",
    "    numb += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 4: Есть ли твиты от одного и того же пользователя? Если да, то сколько таких пользователей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из каждого существующего твита достаю значение по ключу user. Это словарь. Из него вынимаю значение по ключу id. Складываю все id в список. С помощью Counter создаю частотный словарь, затем считаю все значения, не равные 1. Если таких нет, сообщаю, что пользователей по критерию не нашлось, если есть - сообщаю положительный ответ и количество пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Такие пользователи есть. Их количество -  25\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "users = []\n",
    "for twit in existing:\n",
    "    user = twit['user']\n",
    "    iduser = user['id']\n",
    "    users.append(iduser)\n",
    "users = Counter(users)\n",
    "numbusers = 0\n",
    "for value in users.values():\n",
    "    if value != 1:\n",
    "        numbusers += 1\n",
    "if numbusers == 0:\n",
    "    print('Таких пользователей нет.')\n",
    "else:\n",
    "    print('Такие пользователи есть. Их количество - ', numbusers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 5: Топ-20 хэштегов (для них есть специальное поле)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из каждого существующего твита перебором достаю значение по ключу entities, из него - значение по ключу hashtags. Это список словарей. Из каждого словаря перебором по ключу text достаю хэштег, складываю в отдельный список. Объединяю списки тегов для каждого твита в большой список. С помощью Counter и most_common нахожу 20 наиболее употребляемых хэштегов, вывожу результат в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер\t Тег \t\t\t Количество употреблений\n",
      "1 \t BTS \t\t\t 17\n",
      "2 \t 방탄소년단 \t\t\t 13\n",
      "3 \t AMAs \t\t\t 11\n",
      "4 \t 人気投票ガチャ \t\t\t 8\n",
      "5 \t 태형 \t\t\t 7\n",
      "6 \t 뷔 \t\t\t 6\n",
      "7 \t BTSinChicago \t\t\t 5\n",
      "8 \t BTSLoveYourselfTour \t\t\t 5\n",
      "9 \t 오늘의방탄 \t\t\t 5\n",
      "10 \t PledgeForSwachhBharat \t\t\t 5\n",
      "11 \t MPN \t\t\t 5\n",
      "12 \t PCAs \t\t\t 4\n",
      "13 \t V \t\t\t 4\n",
      "14 \t 시카고1회차공연 \t\t\t 4\n",
      "15 \t เป๊กผลิตโชค \t\t\t 4\n",
      "16 \t JIMIN \t\t\t 4\n",
      "17 \t running \t\t\t 3\n",
      "18 \t NCT \t\t\t 3\n",
      "19 \t 지민 \t\t\t 3\n",
      "20 \t WajahmuPlastik \t\t\t 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "allthehashtags = []\n",
    "for twit in existing:\n",
    "    entities = twit['entities']\n",
    "    hashtags = entities['hashtags']\n",
    "    tagsinatwit = []\n",
    "    for text in hashtags:\n",
    "        tag = text['text']\n",
    "        tagsinatwit.append(tag)\n",
    "    allthehashtags.extend(tagsinatwit)\n",
    "allthehashtags = Counter(allthehashtags).most_common(20)\n",
    "numb = 1\n",
    "print('Номер' '\\t', 'Тег', '\\t\\t\\t', 'Количество употреблений')\n",
    "for tag in allthehashtags:\n",
    "    print(numb, '\\t', tag[0], '\\t\\t\\t', tag[1])\n",
    "    numb += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 6: Предобработать тексты оригинальных твитов (не ретвитов) на английском языке (убрать пунктуацию, привести к нижнему регистру) и составить частотный словарь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция делит текст на слова по пробелам, чистит их от знаков, удаляет ссылки, переводит в нижний регистр оставшиеся слова. По отсутствию retweeted_status и quoted_status_id в ключах выбираю из существующих твитов только оригинальные. Вторым циклом проверяю язык трита по ключу lang, применяю функцию очистки текста, складываю все слова в список original_en. С помощью Counter и most_common создаю упорядоченный частотный словарь, вывожу значения в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово \t Количество вхождений\n",
      "the \t 107\n",
      "to \t 79\n",
      "a \t 67\n",
      "i \t 60\n",
      "and \t 58\n",
      "you \t 45\n",
      "is \t 41\n",
      "for \t 40\n",
      "of \t 40\n",
      "it \t 38\n",
      " \t 34\n",
      "in \t 32\n",
      "that \t 30\n",
      "my \t 26\n",
      "on \t 25\n",
      "me \t 25\n",
      "be \t 22\n",
      "this \t 20\n",
      "are \t 20\n",
      "have \t 19\n",
      "so \t 18\n",
      "but \t 17\n",
      "at \t 17\n",
      "your \t 16\n",
      "get \t 16\n",
      "not \t 16\n",
      "more \t 16\n",
      "with \t 16\n",
      "what \t 15\n",
      "just \t 14\n",
      "about \t 13\n",
      "now \t 12\n",
      "up \t 11\n",
      "we \t 11\n",
      "all \t 10\n",
      "only \t 10\n",
      "was \t 10\n",
      "hit \t 10\n",
      "out \t 9\n",
      "today \t 9\n",
      "if \t 9\n",
      "i’m \t 9\n",
      "he \t 9\n",
      "one \t 9\n",
      "who \t 9\n",
      "can \t 8\n",
      "from \t 8\n",
      "an \t 8\n",
      "like \t 8\n",
      "people \t 8\n",
      "they \t 8\n",
      "i'm \t 8\n",
      "it's \t 8\n",
      "know \t 7\n",
      "love \t 7\n",
      "or \t 7\n",
      "its \t 7\n",
      "some \t 7\n",
      "day \t 7\n",
      "as \t 7\n",
      "first \t 7\n",
      "life \t 7\n",
      "still \t 7\n",
      "time \t 6\n",
      "think \t 6\n",
      "our \t 6\n",
      "can’t \t 6\n",
      "good \t 6\n",
      "free \t 6\n",
      "really \t 6\n",
      "amp \t 6\n",
      "by \t 6\n",
      "it’s \t 6\n",
      "didn’t \t 6\n",
      "want \t 6\n",
      "go \t 6\n",
      "way \t 6\n",
      "she \t 6\n",
      "make \t 6\n",
      "him \t 6\n",
      "new \t 6\n",
      "no \t 5\n",
      "her \t 5\n",
      "how \t 5\n",
      "2 \t 5\n",
      "then \t 5\n",
      "gore \t 5\n",
      "need \t 5\n",
      "that’s \t 5\n",
      "been \t 5\n",
      "will \t 5\n",
      "game \t 5\n",
      "than \t 4\n",
      "here \t 4\n",
      "don’t \t 4\n",
      "why \t 4\n",
      "6 \t 4\n",
      "looking \t 4\n",
      "check \t 4\n",
      "always \t 4\n",
      "1 \t 4\n",
      "october \t 4\n",
      "must \t 4\n",
      "best \t 4\n",
      "take \t 4\n",
      "should \t 4\n",
      "team \t 4\n",
      "into \t 4\n",
      "their \t 4\n",
      "off \t 4\n",
      "too \t 4\n",
      "before \t 4\n",
      "c \t 4\n",
      "yet \t 4\n",
      "03 \t 4\n",
      "2018 \t 4\n",
      "because \t 4\n",
      "3 \t 4\n",
      "via \t 4\n",
      "says \t 4\n",
      "better \t 4\n",
      "when \t 4\n",
      "most \t 4\n",
      "real \t 4\n",
      "youtube \t 4\n",
      "video \t 4\n",
      "fuck \t 4\n",
      "own \t 4\n",
      "much \t 4\n",
      "has \t 4\n",
      "top \t 3\n",
      "might \t 3\n",
      "night \t 3\n",
      "these \t 3\n",
      "days \t 3\n",
      "ever \t 3\n",
      "instagram \t 3\n",
      "decision \t 3\n",
      "even \t 3\n",
      "heart \t 3\n",
      "seeing \t 3\n",
      "back \t 3\n",
      "united \t 3\n",
      "haven't \t 3\n",
      "bad \t 3\n",
      "do \t 3\n",
      "utc \t 3\n",
      "wind \t 3\n",
      "n \t 3\n",
      "bar \t 3\n",
      "nothing \t 3\n",
      "next \t 3\n",
      "last \t 3\n",
      "remote \t 3\n",
      "his \t 3\n",
      "them \t 3\n",
      "don't \t 3\n",
      "miss \t 3\n",
      "did \t 3\n",
      "canada \t 3\n",
      "any \t 3\n",
      "hope \t 3\n",
      "hell \t 3\n",
      "live \t 3\n",
      "that's \t 3\n",
      "gonna \t 3\n",
      "since \t 3\n",
      "cute \t 3\n",
      "everyone \t 3\n",
      "business \t 3\n",
      "cest \t 3\n",
      "story \t 3\n",
      "thank \t 3\n",
      "u \t 3\n",
      "seen \t 3\n",
      "wrong \t 3\n",
      "lot \t 3\n",
      "made \t 3\n",
      "got \t 3\n",
      "see \t 3\n",
      "great \t 3\n",
      "sad \t 3\n",
      "cubs \t 3\n",
      "another \t 3\n",
      "run \t 3\n",
      "pardede \t 3\n",
      "you'll \t 2\n",
      "getting \t 2\n",
      "kids \t 2\n",
      "strategy \t 2\n",
      "girls \t 2\n",
      "wait \t 2\n",
      "tonight \t 2\n",
      "tv \t 2\n",
      "personal \t 2\n",
      "sleep \t 2\n",
      "without \t 2\n",
      "current \t 2\n",
      "24h \t 2\n",
      "change \t 2\n",
      "😂 \t 2\n",
      "3rd \t 2\n",
      "morning \t 2\n",
      "things \t 2\n",
      "had \t 2\n",
      "vs \t 2\n",
      "app \t 2\n",
      "coming \t 2\n",
      "could \t 2\n",
      "court \t 2\n",
      "dont \t 2\n",
      "anything \t 2\n",
      "pick \t 2\n",
      "myself \t 2\n",
      "😭 \t 2\n",
      "favorite \t 2\n",
      "years \t 2\n",
      "playing \t 2\n",
      "samsung \t 2\n",
      "draw \t 2\n",
      "ball \t 2\n",
      "0 \t 2\n",
      "light \t 2\n",
      "stand \t 2\n",
      "22 \t 2\n",
      "wants \t 2\n",
      "world \t 2\n",
      "pretty \t 2\n",
      "easy \t 2\n",
      "ones \t 2\n",
      "call \t 2\n",
      "im \t 2\n",
      "loved \t 2\n",
      "after \t 2\n",
      "0.0 \t 2\n",
      "temp \t 2\n",
      "11.0 \t 2\n",
      "max \t 2\n",
      "09-09 \t 2\n",
      "single \t 2\n",
      "dating \t 2\n",
      "🎶 \t 2\n",
      "striving \t 2\n",
      "balance \t 2\n",
      "instinctual \t 2\n",
      "reaction \t 2\n",
      "virgo \t 2\n",
      "e \t 2\n",
      "many \t 2\n",
      "point \t 2\n",
      "each \t 2\n",
      "week \t 2\n",
      "short \t 2\n",
      "59 \t 2\n",
      "suit \t 2\n",
      "post \t 2\n",
      "advisory \t 2\n",
      "told \t 2\n",
      "samygo \t 2\n",
      "following \t 2\n",
      "over \t 2\n",
      "expect \t 2\n",
      "family \t 2\n",
      "there \t 2\n",
      "lol \t 2\n",
      "blockchain \t 2\n",
      "insurance \t 2\n",
      "kid \t 2\n",
      "were \t 2\n",
      "went \t 2\n",
      "tired \t 2\n",
      "bed \t 2\n",
      "hpa \t 2\n",
      "rain \t 2\n",
      "mm \t 2\n",
      "sebgorka \t 2\n",
      "buy \t 2\n",
      "food \t 2\n",
      "maybe \t 2\n",
      "realize \t 2\n",
      "missing \t 2\n",
      "knowing \t 2\n",
      "gotta \t 2\n",
      "cold \t 2\n",
      "walking \t 2\n",
      "super \t 2\n",
      "rare \t 2\n",
      "does \t 2\n",
      "12 \t 2\n",
      "34 \t 2\n",
      "twitter \t 2\n",
      "months \t 2\n",
      "series \t 2\n",
      "second \t 2\n",
      "mother \t 2\n",
      "cancer \t 2\n",
      "felt \t 2\n",
      "l \t 2\n",
      "ok \t 2\n",
      "every \t 2\n",
      "planning \t 2\n",
      "card \t 2\n",
      "lead \t 2\n",
      "watch \t 2\n",
      "eat \t 2\n",
      "north \t 2\n",
      "which \t 2\n",
      "cloudy \t 2\n",
      "high \t 2\n",
      "low \t 2\n",
      "’ \t 2\n",
      "hi \t 2\n",
      "wear \t 2\n",
      "paid \t 2\n",
      "would \t 2\n",
      "shit \t 2\n",
      "taking \t 2\n",
      "lie \t 2\n",
      "man \t 2\n",
      "going \t 2\n",
      "watching \t 2\n",
      "trade \t 2\n",
      "waiting \t 2\n",
      "park \t 2\n",
      "happy \t 2\n",
      "brother \t 2\n",
      "ya \t 2\n",
      "help \t 2\n",
      "mind \t 2\n",
      "answer \t 2\n",
      "sis \t 2\n",
      "gone \t 2\n",
      "w \t 2\n",
      "grade \t 2\n",
      "bc \t 2\n",
      "addition \t 2\n",
      "house \t 2\n",
      "song \t 2\n",
      "took \t 2\n",
      "rome \t 2\n",
      "sure \t 2\n",
      "also \t 2\n",
      "yeah \t 2\n",
      "okay \t 2\n",
      "situation \t 2\n",
      "ump \t 2\n",
      "retribution \t 2\n",
      "strange \t 2\n",
      "truth \t 2\n",
      "let \t 2\n",
      "hour \t 2\n",
      "n’ \t 2\n",
      "artist \t 2\n",
      "recent \t 2\n",
      "picture \t 2\n",
      "thala \t 2\n",
      "sir \t 2\n",
      "running \t 2\n",
      "show \t 2\n",
      "liked \t 2\n",
      "ny \t 2\n",
      "ronaldo \t 2\n",
      "needed \t 2\n",
      "feel \t 2\n",
      "safe \t 2\n",
      "probably \t 2\n",
      "ass \t 2\n",
      "s \t 2\n",
      "sing \t 2\n",
      "reach \t 2\n",
      "keep \t 2\n",
      "season \t 2\n",
      "side \t 2\n",
      "he's \t 2\n",
      "face \t 2\n",
      "she's \t 2\n",
      "legit \t 2\n",
      "baseball \t 2\n",
      "look \t 2\n",
      "kavanaugh \t 2\n",
      "yes \t 2\n",
      "patent \t 2\n",
      "phone \t 2\n",
      "follow \t 2\n",
      "posted \t 2\n",
      "actually \t 2\n",
      "while \t 2\n",
      "say \t 2\n",
      "tatolote \t 1\n",
      "higher \t 1\n",
      "600 \t 1\n",
      "toys \t 1\n",
      "christmas \t 1\n",
      "picks \t 1\n",
      "sharing \t 1\n",
      "videos \t 1\n",
      "essential \t 1\n",
      "digital \t 1\n",
      "wondering \t 1\n",
      "artic \t 1\n",
      "mccalls \t 1\n",
      "m6313 \t 1\n",
      "childrens \t 1\n",
      "tops \t 1\n",
      "dress \t 1\n",
      "belt \t 1\n",
      "ruffle \t 1\n",
      "jeans \t 1\n",
      "sz \t 1\n",
      "cl \t 1\n",
      "7 \t 1\n",
      "8 \t 1\n",
      "ebay \t 1\n",
      "return \t 1\n",
      "australia \t 1\n",
      "tickets/info \t 1\n",
      "sometimes \t 1\n",
      "problematic \t 1\n",
      "abcblackcomedy \t 1\n",
      "continues \t 1\n",
      "9:30pm \t 1\n",
      "abc \t 1\n",
      "cheeky \t 1\n",
      "afte \t 1\n",
      "finance \t 1\n",
      "employment \t 1\n",
      "issues \t 1\n",
      "letting \t 1\n",
      "worry \t 1\n",
      "expert \t 1\n",
      "consu \t 1\n",
      "exercise \t 1\n",
      "worrying \t 1\n",
      "breakouts \t 1\n",
      "rashes \t 1\n",
      "tips \t 1\n",
      "tricks \t 1\n",
      "care \t 1\n",
      "giving \t 1\n",
      "preference.” \t 1\n",
      "14:00:01 \t 1\n",
      "717 \t 1\n",
      "21:39 \t 1\n",
      "user \t 1\n",
      "load \t 1\n",
      "average \t 1\n",
      "1.52 \t 1\n",
      "1.66 \t 1\n",
      "1.72 \t 1\n",
      "50.0°c \t 1\n",
      "btc \t 1\n",
      "price \t 1\n",
      "6,423.75 \t 1\n",
      "2.30 \t 1\n",
      "volume \t 1\n",
      "39,839,710.6 \t 1\n",
      "marketcap \t 1\n",
      "taeilthetic \t 1\n",
      "supposed \t 1\n",
      "compliment \t 1\n",
      "obrigada \t 1\n",
      "yungriix \t 1\n",
      "mine \t 1\n",
      "looked \t 1\n",
      "disastrous \t 1\n",
      "pandey_tisha \t 1\n",
      "songs \t 1\n",
      "long/and \t 1\n",
      "words \t 1\n",
      "sad/why \t 1\n",
      "choose/between \t 1\n",
      "neilyoung \t 1\n",
      "03-oct-18 \t 1\n",
      "10:30 \t 1\n",
      "dollar \t 1\n",
      "rupee \t 1\n",
      "reservebankofindia \t 1\n",
      "rbi \t 1\n",
      "68.6573 \t 1\n",
      "download \t 1\n",
      "android \t 1\n",
      "afraid \t 1\n",
      "ai \t 1\n",
      "job \t 1\n",
      "shouldn't \t 1\n",
      "instead \t 1\n",
      "worried \t 1\n",
      "integrate \t 1\n",
      "astronomers \t 1\n",
      "named \t 1\n",
      "goblin \t 1\n",
      "they've \t 1\n",
      "learned \t 1\n",
      "quite \t 1\n",
      "planet \t 1\n",
      "nine \t 1\n",
      "learn \t 1\n",
      "sell \t 1\n",
      "shop \t 1\n",
      "stories \t 1\n",
      "ads \t 1\n",
      "inc \t 1\n",
      "shane_barker \t 1\n",
      "welcome \t 1\n",
      "biltongbar \t 1\n",
      "click \t 1\n",
      "through \t 1\n",
      "delicious \t 1\n",
      "biltong \t 1\n",
      "recipes \t 1\n",
      "sarah \t 1\n",
      "palin’s \t 1\n",
      "son \t 1\n",
      "track \t 1\n",
      "faces \t 1\n",
      "jail \t 1\n",
      "gaf \t 1\n",
      "anymore \t 1\n",
      "faker \t 1\n",
      "tapos \t 1\n",
      "naaaaaaa \t 1\n",
      "sunburned \t 1\n",
      "hearteuu \t 1\n",
      "part \t 1\n",
      "wowcuppcaake \t 1\n",
      "thetwitchbakery \t 1\n",
      "stream \t 1\n",
      "ago \t 1\n",
      "tombstones \t 1\n",
      "ut2k4 \t 1\n",
      "gaming \t 1\n",
      "server \t 1\n",
      "echo \t 1\n",
      "dm-asbestos \t 1\n",
      "0/16 \t 1\n",
      "players \t 1\n",
      "surface \t 1\n",
      "tempered \t 1\n",
      "film \t 1\n",
      "s8 \t 1\n",
      "plus \t 1\n",
      "manchester \t 1\n",
      "frustrated \t 1\n",
      "valencia \t 1\n",
      "barren \t 1\n",
      "old \t 1\n",
      "trafford \t 1\n",
      "mourinho \t 1\n",
      "nhl \t 1\n",
      "alert \t 1\n",
      "10/3/18 \t 1\n",
      "sponsor \t 1\n",
      "entry \t 1\n",
      "100k \t 1\n",
      "contest \t 1\n",
      "5 \t 1\n",
      "depoist \t 1\n",
      "draftkings \t 1\n",
      "cardboardshark \t 1\n",
      "candles \t 1\n",
      "incense \t 1\n",
      "dissolve \t 1\n",
      "salt \t 1\n",
      "cup \t 1\n",
      "water \t 1\n",
      "eastern \t 1\n",
      "sid \t 1\n",
      "crashed \t 1\n",
      "previous \t 1\n",
      "corners \t 1\n",
      "chances \t 1\n",
      "stack \t 1\n",
      "murray's \t 1\n",
      "motorsportmoments \t 1\n",
      "everybody \t 1\n",
      "rule \t 1\n",
      "1texanmarcy \t 1\n",
      "pftompkins \t 1\n",
      "busyphilipps \t 1\n",
      "separate \t 1\n",
      "reac \t 1\n",
      "prestashop \t 1\n",
      "module \t 1\n",
      "tweeted \t 1\n",
      "times \t 1\n",
      "rachel \t 1\n",
      "marie \t 1\n",
      "writer \t 1\n",
      "sometime \t 1\n",
      "b_los713 \t 1\n",
      "friday \t 1\n",
      "lets \t 1\n",
      "sum \t 1\n",
      "rexchidubem \t 1\n",
      "exactly \t 1\n",
      "annoying \t 1\n",
      "online \t 1\n",
      "seasons \t 1\n",
      "coins \t 1\n",
      "finishing \t 1\n",
      "big \t 1\n",
      "gn \t 1\n",
      "start \t 1\n",
      "remembering \t 1\n",
      "dreams \t 1\n",
      "✔ \t 1\n",
      "0500 \t 1\n",
      "kts \t 1\n",
      "16.6 \t 1\n",
      "11:21 \t 1\n",
      "min \t 1\n",
      "04:57 \t 1\n",
      "dew \t 1\n",
      "pt \t 1\n",
      "9.6 \t 1\n",
      "102 \t 1\n",
      "leo \t 1\n",
      "– \t 1\n",
      "cee-c \t 1\n",
      "smolbaka \t 1\n",
      "sky \t 1\n",
      "calling \t 1\n",
      "burakovsky \t 1\n",
      "thing \t 1\n",
      "lock \t 1\n",
      "outside \t 1\n",
      "rated \t 1\n",
      "sexytimes \t 1\n",
      "ao3 \t 1\n",
      "gbpinr \t 1\n",
      "291018 \t 1\n",
      "current:95.68 \t 1\n",
      "volume:11104 \t 1\n",
      "oi:47534 \t 1\n",
      "oct \t 1\n",
      "10:29:05 \t 1\n",
      "ist \t 1\n",
      "imkorean_too \t 1\n",
      "highest \t 1\n",
      "earn \t 1\n",
      "ticket \t 1\n",
      "kinda \t 1\n",
      "ha \t 1\n",
      "qpac's \t 1\n",
      "taste \t 1\n",
      "priscilla \t 1\n",
      "queen \t 1\n",
      "desert \t 1\n",
      "musical \t 1\n",
      "fabulous \t 1\n",
      "👠 \t 1\n",
      "28 \t 1\n",
      "hours \t 1\n",
      "minutes \t 1\n",
      "seconds \t 1\n",
      "until \t 1\n",
      "icos \t 1\n",
      "gosayyay \t 1\n",
      "quotes \t 1\n",
      "freshly \t 1\n",
      "created \t 1\n",
      "2016 \t 1\n",
      "2017 \t 1\n",
      "enjoy \t 1\n",
      "whatsappstatus \t 1\n",
      "latestquotes \t 1\n",
      "felda \t 1\n",
      "land \t 1\n",
      "deal \t 1\n",
      "judge \t 1\n",
      "recuses \t 1\n",
      "herself \t 1\n",
      "sun \t 1\n",
      "joe \t 1\n",
      "tj604e \t 1\n",
      "electric \t 1\n",
      "garden \t 1\n",
      "tiller \t 1\n",
      "16-inch \t 1\n",
      "13.5a \t 1\n",
      "certified \t 1\n",
      "refurbished \t 1\n",
      "wildcard \t 1\n",
      "gifted \t 1\n",
      "malone \t 1\n",
      "25k \t 1\n",
      "gold \t 1\n",
      "bike \t 1\n",
      "prankclips \t 1\n",
      "funny \t 1\n",
      "prank \t 1\n",
      "iconflow215 \t 1\n",
      "airing \t 1\n",
      "soon \t 1\n",
      "airitoutradio \t 1\n",
      "24/7 \t 1\n",
      "station...click \t 1\n",
      "link \t 1\n",
      "red \t 1\n",
      "hat \t 1\n",
      "security \t 1\n",
      "2018-2857-01 \t 1\n",
      "sewer \t 1\n",
      "trump \t 1\n",
      "saudi \t 1\n",
      "king \t 1\n",
      "wouldn't \t 1\n",
      "us \t 1\n",
      "support \t 1\n",
      "presstv \t 1\n",
      "allows \t 1\n",
      "control \t 1\n",
      "tvs \t 1\n",
      "local \t 1\n",
      "network \t 1\n",
      "using \t 1\n",
      "wi \t 1\n",
      "beto \t 1\n",
      "o’rourke \t 1\n",
      "passenger \t 1\n",
      "backs \t 1\n",
      "claim \t 1\n",
      "fleeing \t 1\n",
      "1998 \t 1\n",
      "dui \t 1\n",
      "crash \t 1\n",
      "daze \t 1\n",
      "helps \t 1\n",
      "become \t 1\n",
      "disappointed \t 1\n",
      "explain \t 1\n",
      "yourself \t 1\n",
      "loves \t 1\n",
      "they’ll \t 1\n",
      "leightongrahame \t 1\n",
      "course \t 1\n",
      "😊 \t 1\n",
      "drive \t 1\n",
      "😄 \t 1\n",
      "impact \t 1\n",
      "industry \t 1\n",
      "insurtech \t 1\n",
      "customer \t 1\n",
      "churn \t 1\n",
      "usa \t 1\n",
      "gdp \t 1\n",
      "end \t 1\n",
      "customeracquisition \t 1\n",
      "addiction \t 1\n",
      "interesting \t 1\n",
      "parts \t 1\n",
      "creation \t 1\n",
      "obscure \t 1\n",
      "instruments \t 1\n",
      "used \t 1\n",
      "during \t 1\n",
      "cre \t 1\n",
      "rss \t 1\n",
      "feed \t 1\n",
      "url \t 1\n",
      "deprecated \t 1\n",
      "shizukus \t 1\n",
      "wide \t 1\n",
      "awake \t 1\n",
      "2.2 \t 1\n",
      "mph \t 1\n",
      "wnw \t 1\n",
      "barometer \t 1\n",
      "1009.0 \t 1\n",
      "rising \t 1\n",
      "slowly \t 1\n",
      "temperature \t 1\n",
      "11.9 \t 1\n",
      "°c \t 1\n",
      "humidity \t 1\n",
      "90 \t 1\n",
      "eloraflora88 \t 1\n",
      "daninew18 \t 1\n",
      "public \t 1\n",
      "same \t 1\n",
      "pretend \t 1\n",
      "burn \t 1\n",
      "witches \t 1\n",
      "beauty \t 1\n",
      "greater \t 1\n",
      "recommendation \t 1\n",
      "letter \t 1\n",
      "reference \t 1\n",
      "health \t 1\n",
      "04:59 \t 1\n",
      "imbecile \t 1\n",
      "excuses \t 1\n",
      "🤗 \t 1\n",
      "flat \t 1\n",
      "whites \t 1\n",
      "fast \t 1\n",
      "where \t 1\n",
      "uk \t 1\n",
      "buys \t 1\n",
      "coffee \t 1\n",
      "gulaaaaaaa \t 1\n",
      "weyh \t 1\n",
      "slide \t 1\n",
      "camni \t 1\n",
      "sees \t 1\n",
      "trusts \t 1\n",
      "believes \t 1\n",
      "kn \t 1\n",
      "you’ll \t 1\n",
      "wake \t 1\n",
      "calls \t 1\n",
      "hurt \t 1\n",
      "possibility \t 1\n",
      "heaven \t 1\n",
      "aint \t 1\n",
      "9 \t 1\n",
      "sweet \t 1\n",
      "busy \t 1\n",
      "philipps \t 1\n",
      "michelle \t 1\n",
      "williams \t 1\n",
      "said \t 1\n",
      "friendship \t 1\n",
      "dawson \t 1\n",
      "itsevandaniel \t 1\n",
      "oyeronke \t 1\n",
      "classic \t 1\n",
      "example \t 1\n",
      "copy \t 1\n",
      "paste😀 \t 1\n",
      "drunk \t 1\n",
      "fight \t 1\n",
      "friends \t 1\n",
      "lmao \t 1\n",
      "y’all \t 1\n",
      "thought \t 1\n",
      "month \t 1\n",
      "comics \t 1\n",
      "dead \t 1\n",
      "163 \t 1\n",
      "retailer \t 1\n",
      "colour \t 1\n",
      "variant \t 1\n",
      "1:200 \t 1\n",
      "comic \t 1\n",
      "bubbafartbucket \t 1\n",
      "usually \t 1\n",
      "martergarter \t 1\n",
      "yup \t 1\n",
      "mayweather \t 1\n",
      "mcgregor \t 1\n",
      "apr \t 1\n",
      "2015 \t 1\n",
      "me.😉 \t 1\n",
      "899 \t 1\n",
      "split \t 1\n",
      "bk1 \t 1\n",
      "hybrid \t 1\n",
      "plunge \t 1\n",
      "mount \t 1\n",
      "1st \t 1\n",
      "rung \t 1\n",
      "mi5 \t 1\n",
      "thrillers \t 1\n",
      "ladder \t 1\n",
      "lost \t 1\n",
      "someone \t 1\n",
      "breast \t 1\n",
      "loss \t 1\n",
      "expected \t 1\n",
      "everyhourr23-11-20161 \t 1\n",
      "test \t 1\n",
      "2018,10,03 \t 1\n",
      "01:00:15 \t 1\n",
      "odds \t 1\n",
      "maluma \t 1\n",
      "noticing \t 1\n",
      "comment \t 1\n",
      "“i \t 1\n",
      "you” \t 1\n",
      "drink \t 1\n",
      "henny \t 1\n",
      "trips \t 1\n",
      "stresses \t 1\n",
      "😂🙂😅 \t 1\n",
      "affordable \t 1\n",
      "quick \t 1\n",
      "design \t 1\n",
      "services \t 1\n",
      "auxano \t 1\n",
      "businesscard \t 1\n",
      "bestbusinesscard \t 1\n",
      "06:58 \t 1\n",
      "lincolnbrewster \t 1\n",
      "letyourgloryshine \t 1\n",
      "rock \t 1\n",
      "radio \t 1\n",
      "today's \t 1\n",
      "dance \t 1\n",
      "「silk \t 1\n",
      "city \t 1\n",
      "dua \t 1\n",
      "lipa」's \t 1\n",
      "『electricity \t 1\n",
      "feat \t 1\n",
      "diplo \t 1\n",
      "mark \t 1\n",
      "ronson)』 \t 1\n",
      "bless \t 1\n",
      "boo \t 1\n",
      "finna \t 1\n",
      "naruto \t 1\n",
      "mozzarella \t 1\n",
      "sticks \t 1\n",
      "onion \t 1\n",
      "rings \t 1\n",
      "here's \t 1\n",
      "long-term \t 1\n",
      "tax \t 1\n",
      "bracket \t 1\n",
      "management \t 1\n",
      "increase \t 1\n",
      "tax-efficiency \t 1\n",
      "retirement \t 1\n",
      "portfolio \t 1\n",
      "anyone \t 1\n",
      "harness \t 1\n",
      "power \t 1\n",
      "emotional \t 1\n",
      "energy \t 1\n",
      "scorpio \t 1\n",
      "south \t 1\n",
      "headed \t 1\n",
      "visit \t 1\n",
      "melbourne \t 1\n",
      "06:56 \t 1\n",
      "understand \t 1\n",
      "dns \t 1\n",
      "servers \t 1\n",
      "persistently \t 1\n",
      "difficult \t 1\n",
      "fostah \t 1\n",
      "hahahah \t 1\n",
      "i'll \t 1\n",
      "try \t 1\n",
      "sunrise \t 1\n",
      "05:49am \t 1\n",
      "partly \t 1\n",
      "of:23 \t 1\n",
      "nice \t 1\n",
      "24 \t 1\n",
      "devoted \t 1\n",
      "car \t 1\n",
      "ripping \t 1\n",
      "seams \t 1\n",
      "wanted \t 1\n",
      "mkbhd \t 1\n",
      "smartwatch \t 1\n",
      "usual \t 1\n",
      "stuff \t 1\n",
      "gps \t 1\n",
      "hartrate \t 1\n",
      "sensor \t 1\n",
      "os \t 1\n",
      "seems \t 1\n",
      "f \t 1\n",
      "elj1329 \t 1\n",
      "andallorie \t 1\n",
      "vhilms \t 1\n",
      "aldubeth02 \t 1\n",
      "pinkyfaye \t 1\n",
      "latuazon \t 1\n",
      "jegi18 \t 1\n",
      "wengcookie \t 1\n",
      "noemicaseres53 \t 1\n",
      "sakurakharel \t 1\n",
      "unremarkable \t 1\n",
      "place \t 1\n",
      "unspeakable \t 1\n",
      "evil \t 1\n",
      "sugar \t 1\n",
      "creek \t 1\n",
      "cinnamontoastk \t 1\n",
      "impossible \t 1\n",
      "talk \t 1\n",
      "sports \t 1\n",
      "nl \t 1\n",
      "west \t 1\n",
      "playoffs \t 1\n",
      "judged \t 1\n",
      "reason \t 1\n",
      "sucks \t 1\n",
      "chance \t 1\n",
      "isn't \t 1\n",
      "worth \t 1\n",
      "shift \t 1\n",
      "tide \t 1\n",
      "barely \t 1\n",
      "perceptible \t 1\n",
      "living \t 1\n",
      "y'all \t 1\n",
      "eyeing \t 1\n",
      "shock \t 1\n",
      "loan \t 1\n",
      "move \t 1\n",
      "veteran \t 1\n",
      "swedish \t 1\n",
      "defender \t 1\n",
      "tallest \t 1\n",
      "height \t 1\n",
      "called \t 1\n",
      "titanic \t 1\n",
      "already \t 1\n",
      "part💀 \t 1\n",
      "pact \t 1\n",
      "clause \t 1\n",
      "deterring \t 1\n",
      "china \t 1\n",
      "deals \t 1\n",
      "lokol \t 1\n",
      "stalbert \t 1\n",
      "tatumnicoleee \t 1\n",
      "disappoint \t 1\n",
      "everyday \t 1\n",
      "🤷🏽‍♂️🤷🏽‍♂️🤷🏽‍♂️ \t 1\n",
      "upstephanie \t 1\n",
      "st \t 1\n",
      "albert \t 1\n",
      "sherwood \t 1\n",
      "consider \t 1\n",
      "themselves \t 1\n",
      "town \t 1\n",
      "convenient \t 1\n",
      "didnt \t 1\n",
      "alexjferraro \t 1\n",
      "🙏🙏 \t 1\n",
      "birthday \t 1\n",
      "talejo \t 1\n",
      "baby🤨❤️ \t 1\n",
      "owners \t 1\n",
      "riverside \t 1\n",
      "ca \t 1\n",
      "employee \t 1\n",
      "problem \t 1\n",
      "join \t 1\n",
      "board \t 1\n",
      "directors \t 1\n",
      "martines \t 1\n",
      "hwy \t 1\n",
      "4 \t 1\n",
      "westbound \t 1\n",
      "driver \t 1\n",
      "struck \t 1\n",
      "several \t 1\n",
      "vehicles \t 1\n",
      "delays \t 1\n",
      "wb4 \t 1\n",
      "cummings \t 1\n",
      "skyway \t 1\n",
      "asks \t 1\n",
      "questions \t 1\n",
      "alone \t 1\n",
      "tod \t 1\n",
      "pisces \t 1\n",
      "news \t 1\n",
      "nag \t 1\n",
      "resign \t 1\n",
      "na \t 1\n",
      "si \t 1\n",
      "mocha \t 1\n",
      "😂😂😂👍👍👍👍 \t 1\n",
      "mood \t 1\n",
      "ivaaaania \t 1\n",
      "doing \t 1\n",
      "act \t 1\n",
      "postbigfines \t 1\n",
      "around \t 1\n",
      "yeast \t 1\n",
      "infection \t 1\n",
      "google \t 1\n",
      "optimise \t 1\n",
      "site \t 1\n",
      "rankings \t 1\n",
      "seo \t 1\n",
      "training \t 1\n",
      "broken \t 1\n",
      "text \t 1\n",
      "seventh \t 1\n",
      "hurting \t 1\n",
      "chanc \t 1\n",
      "unique \t 1\n",
      "style \t 1\n",
      "putting \t 1\n",
      "external \t 1\n",
      "conditions \t 1\n",
      "capricorn \t 1\n",
      "anthonyvito \t 1\n",
      "you’re \t 1\n",
      "🤔 \t 1\n",
      "making \t 1\n",
      "regular \t 1\n",
      "principal \t 1\n",
      "contributions \t 1\n",
      "payment \t 1\n",
      "mortgage \t 1\n",
      "lexiialijaii \t 1\n",
      "nagaland \t 1\n",
      "22nd \t 1\n",
      "open \t 1\n",
      "defecation \t 1\n",
      "state \t 1\n",
      "india \t 1\n",
      "ouch \t 1\n",
      "home \t 1\n",
      "plate \t 1\n",
      "umpire \t 1\n",
      "full \t 1\n",
      "brunt \t 1\n",
      "pitch \t 1\n",
      "06:59 \t 1\n",
      "tamia_nico \t 1\n",
      "naw \t 1\n",
      "appreciate \t 1\n",
      "technology \t 1\n",
      "whole \t 1\n",
      "vibe \t 1\n",
      "mostly \t 1\n",
      "sunny \t 1\n",
      "80f \t 1\n",
      "57f \t 1\n",
      "italy \t 1\n",
      "sister \t 1\n",
      "won’t \t 1\n",
      "spider-man \t 1\n",
      "spider \t 1\n",
      "verse \t 1\n",
      "december \t 1\n",
      "applications \t 1\n",
      "sibli \t 1\n",
      "14:00 \t 1\n",
      "daisyxsock \t 1\n",
      "o \t 1\n",
      "whos \t 1\n",
      "periscope \t 1\n",
      "q&amp;a \t 1\n",
      "woe \t 1\n",
      "generation \t 1\n",
      "advice \t 1\n",
      "prayer \t 1\n",
      "eggdrp \t 1\n",
      "golive \t 1\n",
      "periscopetv \t 1\n",
      "lose \t 1\n",
      "appeal \t 1\n",
      "they’re \t 1\n",
      "turning \t 1\n",
      "television \t 1\n",
      "theme \t 1\n",
      "fl \t 1\n",
      "broward \t 1\n",
      "hollywood \t 1\n",
      "11thhour \t 1\n",
      "dire \t 1\n",
      "emergency \t 1\n",
      "message \t 1\n",
      "proven \t 1\n",
      "pathological \t 1\n",
      "liar \t 1\n",
      "idea \t 1\n",
      "ily \t 1\n",
      "bihh \t 1\n",
      "ilyt \t 1\n",
      "opshinobi \t 1\n",
      "hate \t 1\n",
      "sakura \t 1\n",
      "doesnt \t 1\n",
      "dad \t 1\n",
      "wtf \t 1\n",
      "xradius \t 1\n",
      "i’ve \t 1\n",
      "tight \t 1\n",
      "financially \t 1\n",
      "class \t 1\n",
      "requiring \t 1\n",
      "spendi \t 1\n",
      "vlmhma \t 1\n",
      "senate \t 1\n",
      "sandu787 \t 1\n",
      "replied \t 1\n",
      "dm \t 1\n",
      "kindly \t 1\n",
      "tar \t 1\n",
      "fucking \t 1\n",
      "name \t 1\n",
      "jtb22297 \t 1\n",
      "least \t 1\n",
      "drilled \t 1\n",
      "smoke \t 1\n",
      "wood \t 1\n",
      "survive \t 1\n",
      "becoming \t 1\n",
      "avatar \t 1\n",
      "daughter \t 1\n",
      "leave \t 1\n",
      "06:45 \t 1\n",
      "9.6°c \t 1\n",
      "hum \t 1\n",
      "74 \t 1\n",
      "dewp \t 1\n",
      "4.1°c \t 1\n",
      "1024.4 \t 1\n",
      "196° \t 1\n",
      "11.2 \t 1\n",
      "km/h \t 1\n",
      "fuckinghqze \t 1\n",
      "valebillz \t 1\n",
      "dare_jonson \t 1\n",
      "villainrespi \t 1\n",
      "wplls \t 1\n",
      "forward \t 1\n",
      "“hit \t 1\n",
      "batter” \t 1\n",
      "winnbooker \t 1\n",
      "dpthekid \t 1\n",
      "cj_barrett9 \t 1\n",
      "zekeshutdown24 \t 1\n",
      "lilbigbrother \t 1\n",
      "bossman_bam59 \t 1\n",
      "mr3_2 \t 1\n",
      "lived \t 1\n",
      "purpose \t 1\n",
      "discover \t 1\n",
      "nathisounds \t 1\n",
      "😇🤗 \t 1\n",
      "bigdickbigego \t 1\n",
      "lethargiccommie \t 1\n",
      "video_relaxants \t 1\n",
      "technically \t 1\n",
      "failed \t 1\n",
      "pseudo-nation \t 1\n",
      "tried \t 1\n",
      "ex \t 1\n",
      "01:00pm#mrpoints \t 1\n",
      "staydc \t 1\n",
      "macdonald \t 1\n",
      "sorry \t 1\n",
      "turned \t 1\n",
      "sappy \t 1\n",
      "money \t 1\n",
      "marijuanablunts \t 1\n",
      "yaboysavage \t 1\n",
      "😢 \t 1\n",
      "dom \t 1\n",
      "how’d \t 1\n",
      "congratulations \t 1\n",
      "victryant \t 1\n",
      "starting \t 1\n",
      "very \t 1\n",
      "label \t 1\n",
      "gun \t 1\n",
      "😈🏆 \t 1\n",
      "guns \t 1\n",
      "review \t 1\n",
      "innovation \t 1\n",
      "agency \t 1\n",
      "plans \t 1\n",
      "major \t 1\n",
      "push \t 1\n",
      "startups \t 1\n",
      "ajith \t 1\n",
      "fan \t 1\n",
      "viswasam \t 1\n",
      "problems \t 1\n",
      "fit \t 1\n",
      "stick \t 1\n",
      "cantact \t 1\n",
      "safety \t 1\n",
      "per \t 1\n",
      "‘reeva \t 1\n",
      "pack’ \t 1\n",
      "statistics \t 1\n",
      "leaving \t 1\n",
      "abusive \t 1\n",
      "relatio \t 1\n",
      "haunting \t 1\n",
      "el \t 1\n",
      "paso \t 1\n",
      "high!🎃👻🔪 \t 1\n",
      "wrote \t 1\n",
      "14 \t 1\n",
      "page \t 1\n",
      "paper \t 1\n",
      "something \t 1\n",
      "am \t 1\n",
      "livid \t 1\n",
      "dutch \t 1\n",
      "bank \t 1\n",
      "sentences \t 1\n",
      "teenage \t 1\n",
      "ddos \t 1\n",
      "culprit \t 1\n",
      "community \t 1\n",
      "service \t 1\n",
      "sarahpalinusa \t 1\n",
      "fantastic \t 1\n",
      "tju \t 1\n",
      "wife \t 1\n",
      "forever \t 1\n",
      "marriage \t 1\n",
      "license \t 1\n",
      "robynslov \t 1\n",
      "little \t 1\n",
      "monsters \t 1\n",
      "compare \t 1\n",
      "gaga \t 1\n",
      "wonderful \t 1\n",
      "😂👍 \t 1\n",
      "shewhoblesses \t 1\n",
      "enough \t 1\n",
      "ford \t 1\n",
      "ex-boyfriend \t 1\n",
      "helped \t 1\n",
      "friend \t 1\n",
      "prep \t 1\n",
      "potential \t 1\n",
      "polygraph \t 1\n",
      "pro2ndamendment \t 1\n",
      "finding \t 1\n",
      "former \t 1\n",
      "ferns \t 1\n",
      "hc \t 1\n",
      "andreas \t 1\n",
      "heraf's \t 1\n",
      "actions \t 1\n",
      "crossed \t 1\n",
      "line \t 1\n",
      "bullying \t 1\n",
      "harassment \t 1\n",
      "hookups \t 1\n",
      "sign \t 1\n",
      "email \t 1\n",
      "credit \t 1\n",
      "simple \t 1\n",
      "caught \t 1\n",
      "breaks \t 1\n",
      "slightest \t 1\n",
      "japan \t 1\n",
      "coronating \t 1\n",
      "naito \t 1\n",
      "fukuoka \t 1\n",
      "rather \t 1\n",
      "osaka \t 1\n",
      "optics \t 1\n",
      "cons \t 1\n",
      "hot \t 1\n",
      "wings \t 1\n",
      "darnold_szn \t 1\n",
      "360ffb \t 1\n",
      "matters \t 1\n",
      "cook \t 1\n",
      "dalvin \t 1\n",
      "jared \t 1\n",
      "passion😍 \t 1\n",
      "yanksgalaxy28 \t 1\n",
      "kicked \t 1\n",
      "sarcasm_blood \t 1\n",
      "ruling_planet \t 1\n",
      "needs \t 1\n",
      "either \t 1\n",
      "sweet___ash \t 1\n",
      "tough \t 1\n",
      "bet \t 1\n",
      "anyway \t 1\n",
      "casause \t 1\n",
      "12:00am \t 1\n",
      "knew \t 1\n",
      "😂😂 \t 1\n",
      "currently \t 1\n",
      "11°c \t 1\n",
      "16°c \t 1\n",
      "kingdom \t 1\n",
      "mytholmroyd \t 1\n",
      "rolling \t 1\n",
      "nigga!😂 \t 1\n",
      "taylorj5697 \t 1\n",
      "baby \t 1\n",
      "being \t 1\n",
      "incredible \t 1\n",
      "amazing \t 1\n",
      "thoughtful \t 1\n",
      "girl!!😘😘 \t 1\n",
      "music \t 1\n",
      "daily \t 1\n",
      "unfollower \t 1\n",
      "crowdfire \t 1\n",
      "doesn't \t 1\n",
      "trick \t 1\n",
      "bxgxshannon \t 1\n",
      "saksakcherry \t 1\n",
      "kirinjeu \t 1\n",
      "both \t 1\n",
      "basically \t 1\n",
      "mrmadee \t 1\n",
      "thx \t 1\n",
      "bro \t 1\n",
      "wish \t 1\n",
      "sarkar \t 1\n",
      "rednationrising \t 1\n",
      "ocasio-cortez \t 1\n",
      "ignorant \t 1\n",
      "aims \t 1\n",
      "yhsdior \t 1\n",
      "rea \t 1\n",
      "y \t 1\n",
      "offense \t 1\n",
      "hits \t 1\n",
      "muster \t 1\n",
      "weak \t 1\n",
      "contact \t 1\n",
      "oreojoker \t 1\n",
      "ain't \t 1\n",
      "question \t 1\n",
      "dude \t 1\n",
      "spent \t 1\n",
      "fx \t 1\n",
      "ea \t 1\n",
      "right \t 1\n",
      "market \t 1\n",
      "winning \t 1\n",
      "genius \t 1\n",
      "cespedesbbq \t 1\n",
      "put \t 1\n",
      "theoutpost \t 1\n",
      "kinseip \t 1\n",
      "riled \t 1\n",
      "controversial \t 1\n",
      "topics \t 1\n",
      "e1 \t 1\n",
      "p4 \t 1\n",
      "telling \t 1\n",
      "daniel \t 1\n",
      "stop \t 1\n",
      "wearing \t 1\n",
      "long \t 1\n",
      "socks \t 1\n",
      "slides \t 1\n",
      "bts_bighit \t 1\n",
      "working \t 1\n",
      "hard \t 1\n",
      "boys \t 1\n",
      "💜💜💜💜 \t 1\n",
      "superb \t 1\n",
      "😄💜 \t 1\n",
      "acbryhn \t 1\n",
      "ping \t 1\n",
      "aquaticphyto \t 1\n",
      "clearing \t 1\n",
      "breaking \t 1\n",
      "again \t 1\n",
      "😕why \t 1\n",
      "swear \t 1\n",
      "destined \t 1\n",
      "screen \t 1\n",
      "mommywifelife7 \t 1\n",
      "holding \t 1\n",
      "purple \t 1\n",
      "shirt \t 1\n",
      "lmfao \t 1\n",
      "jk \t 1\n",
      "saw \t 1\n",
      "seem \t 1\n",
      "juliedicaro \t 1\n",
      "mitchrosen670 \t 1\n",
      "turn \t 1\n",
      "lakers \t 1\n",
      "🧐🧐🧐 \t 1\n",
      "rt \t 1\n",
      "nicekicks \t 1\n",
      "nike's \t 1\n",
      "oil \t 1\n",
      "grey \t 1\n",
      "air \t 1\n",
      "deluxe \t 1\n",
      "spilled \t 1\n",
      "retail \t 1\n",
      "andrew_559 \t 1\n",
      "2nd \t 1\n",
      "person \t 1\n",
      "private \t 1\n",
      "😆 \t 1\n",
      "thai \t 1\n",
      "village \t 1\n",
      "🌅 \t 1\n",
      "wednesday \t 1\n",
      "🤓🤓 \t 1\n",
      "humpday \t 1\n",
      "💋✌️ \t 1\n",
      "frankly \t 1\n",
      "gods \t 1\n",
      "stupidest \t 1\n",
      "administer \t 1\n",
      "coldervibes \t 1\n",
      "jaxxrivaro \t 1\n",
      "thiszer0 \t 1\n",
      "superstonereco1 \t 1\n",
      "thanks \t 1\n",
      "🙏 \t 1\n",
      "mika \t 1\n",
      "impulsively \t 1\n",
      "wee-wooing \t 1\n",
      "escape \t 1\n",
      "gwen \t 1\n",
      "stefani \t 1\n",
      "elizabeth \t 1\n",
      "smart \t 1\n",
      "tedxuniversityofnevada \t 1\n",
      "eyes \t 1\n",
      "eye \t 1\n",
      "dk \t 1\n",
      "happened \t 1\n",
      "sako \t 1\n",
      "we’re \t 1\n",
      "screwed \t 1\n",
      "ngaudiano \t 1\n",
      "confirmed \t 1\n",
      "recused \t 1\n",
      "watched \t 1\n",
      "scotus \t 1\n",
      "history \t 1\n",
      "agustdvee \t 1\n",
      "jdjdksks \t 1\n",
      "i’ll \t 1\n",
      "frame \t 1\n",
      "travel \t 1\n",
      "tour \t 1\n",
      "company \t 1\n",
      "myanmar \t 1\n",
      "scared \t 1\n",
      "🤦🏽‍♀️ \t 1\n",
      "iankenyonnfl \t 1\n",
      "thomas \t 1\n",
      "sense \t 1\n",
      "qb \t 1\n",
      "kyles \t 1\n",
      "plan \t 1\n",
      "pursue \t 1\n",
      "unfollowed \t 1\n",
      "mad \t 1\n",
      "ig \t 1\n",
      "volunteer \t 1\n",
      "delivers \t 1\n",
      "monthly \t 1\n",
      "meeting \t 1\n",
      "networking \t 1\n",
      "hear \t 1\n",
      "premiertaxuk \t 1\n",
      "johncardillo \t 1\n",
      "pathetic \t 1\n",
      "schmuck \t 1\n",
      "tuck \t 1\n",
      "tail \t 1\n",
      "required \t 1\n",
      "bravery \t 1\n",
      "papertiger \t 1\n",
      "absolutely \t 1\n",
      "depressing \t 1\n",
      "having \t 1\n",
      "pluckers \t 1\n",
      "near \t 1\n",
      "crave \t 1\n",
      "far \t 1\n",
      "p.155 \t 1\n",
      "once \t 1\n",
      "established \t 1\n",
      "legal \t 1\n",
      "costs \t 1\n",
      "successfully \t 1\n",
      "defend \t 1\n",
      "capitalized \t 1\n",
      "bluffy04 \t 1\n",
      "straightest \t 1\n",
      "ive \t 1\n",
      "shes \t 1\n",
      "porn \t 1\n",
      "tf \t 1\n",
      "thinks \t 1\n",
      "distance \t 1\n",
      "reflex \t 1\n",
      "shirou \t 1\n",
      "straighter \t 1\n",
      "fall \t 1\n",
      "kevinprobably \t 1\n",
      "tuesday \t 1\n",
      "d \t 1\n",
      "donuts \t 1\n",
      "1dbd0b94-2282-4603-9e5a-8f809a7b072a \t 1\n",
      "04:58 \t 1\n",
      "showdown \t 1\n",
      "intense \t 1\n",
      "inktober \t 1\n",
      "drawing \t 1\n",
      "sketch \t 1\n",
      "kamenrider \t 1\n",
      "fanart \t 1\n",
      "ink \t 1\n",
      "miniso \t 1\n",
      "anatomy \t 1\n",
      "learning \t 1\n",
      "ultimaterpe \t 1\n",
      "gahyeon \t 1\n",
      "please \t 1\n",
      "dominos_india \t 1\n",
      "dominos \t 1\n",
      "gotten \t 1\n",
      "refund \t 1\n",
      "screenshot \t 1\n",
      "false \t 1\n",
      "promis \t 1\n",
      "facepalming \t 1\n",
      "self \t 1\n",
      "bruh \t 1\n",
      "photo \t 1\n",
      "hanging \t 1\n",
      "shanakascore \t 1\n",
      "ask \t 1\n",
      "godzillasheart \t 1\n",
      "adela__h \t 1\n",
      "khurrammki \t 1\n",
      "ohsoyoumel \t 1\n",
      "mariumali \t 1\n",
      "states \t 1\n",
      "aren't \t 1\n",
      "america \t 1\n",
      "cubsgirl23 \t 1\n",
      "outdoor \t 1\n",
      "cat \t 1\n",
      "he’s \t 1\n",
      "sound \t 1\n",
      "asleep \t 1\n",
      "t \t 1\n",
      "chohan1954 \t 1\n",
      "vikramwkarve \t 1\n",
      "satishbahri \t 1\n",
      "kayjay34350 \t 1\n",
      "brigtejinder \t 1\n",
      "cmseth1 \t 1\n",
      "true \t 1\n",
      "tan-colored \t 1\n",
      "wool \t 1\n",
      "yellow \t 1\n",
      "blouse \t 1\n",
      "rosa-p.86 \t 1\n",
      "footage \t 1\n",
      "leaks \t 1\n",
      "mysterious \t 1\n",
      "harry \t 1\n",
      "potter \t 1\n",
      "rpg \t 1\n",
      "10 \t 1\n",
      "💙 \t 1\n",
      "roboticcrab \t 1\n",
      "logfromblammo \t 1\n",
      "well \t 1\n",
      "octopus \t 1\n",
      "🐙 \t 1\n",
      "rethink \t 1\n",
      "whatever \t 1\n",
      "facebook \t 1\n",
      "trying \t 1\n",
      "figure \t 1\n",
      "there’s \t 1\n",
      "ravaged \t 1\n",
      "a**hole \t 1\n",
      "tl \t 1\n",
      "seagg-brily \t 1\n",
      "milking \t 1\n",
      "didn't \t 1\n",
      "soniafurstenau \t 1\n",
      "article \t 1\n",
      "literally \t 1\n",
      "ignores \t 1\n",
      "research \t 1\n",
      "claiming \t 1\n",
      "discuss \t 1\n",
      "latest \t 1\n",
      "resear \t 1\n",
      "cosplayers \t 1\n",
      "remember \t 1\n",
      "fact \t 1\n"
     ]
    }
   ],
   "source": [
    "def clearthetext(text):\n",
    "    text = text.split()\n",
    "    cleartext = []\n",
    "    for word in text:\n",
    "        word = word.strip('!\"#$%&\\'-()*+,./:;<=>?@[\\\\]^_`{|}~«»—…')\n",
    "        if not word.startswith('http'):\n",
    "            word = word.lower()\n",
    "            cleartext.append(word)\n",
    "    return cleartext\n",
    "\n",
    "\n",
    "original = []\n",
    "for twit in existing:\n",
    "    if ('retweeted_status' not in twit)and('quoted_status_id' not in twit):\n",
    "        original.append(twit)\n",
    "original_en = []\n",
    "for twit in original:\n",
    "    if twit['lang'] == 'en':\n",
    "        words = clearthetext(twit['text'])\n",
    "        original_en.extend(words)\n",
    "total = Counter(original_en).most_common()\n",
    "print('Слово', '\\t', 'Количество вхождений')\n",
    "for word in total:\n",
    "    print(word[0], '\\t', word[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 7: Найти количество подписчиков (фолловеров) у авторов твитов и вывести топ-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди существующих твитов выделяю информацию о пользователях в отдельный список, избегая повторений.  После этого перебираю получившийся список и составляю список кортежей со значениями \"имя\" и \"количество подписчиков\". Сортирую получившийся список с помощью sorted и функции lambda, для удобства переворачиваю сортировку, чтобы она происходила по убыванию. С помощью цикла и счетчика вывожу первые 10 пользователей и их фолловеров в виде таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер \t Имя \t\t Количество подписчиков\n",
      "1 \t Filosofía♕ \t\t 2521403\n",
      "2 \t FITNESS Magazine \t\t 1491309\n",
      "3 \t malaysiakini.com \t\t 1206759\n",
      "4 \t NYT Science \t\t 1137374\n",
      "5 \t Gramática \t\t 625463\n",
      "6 \t TGRT Haber \t\t 392472\n",
      "7 \t The Sun Football ⚽ \t\t 383698\n",
      "8 \t Melbourne, Australia \t\t 374222\n",
      "9 \t Roznama Express \t\t 318189\n",
      "10 \t 💞 ცųཞɠɛཞცơơɠıɛ 💞 \t\t 311319\n"
     ]
    }
   ],
   "source": [
    "allusers = []\n",
    "allusersid = []\n",
    "for twit in existing:\n",
    "    user = twit['user']\n",
    "    if user['id'] not in allusersid:\n",
    "        allusers.append(user)\n",
    "        allusersid.append(user['id'])\n",
    "userlist = []\n",
    "for user in allusers:\n",
    "    name = user['name']\n",
    "    followers = int(user['followers_count'])\n",
    "    pair = (name, followers)\n",
    "    userlist.append(pair)\n",
    "sorteduserlist = sorted(userlist, key=lambda x: x[1], reverse=True)\n",
    "n = 1\n",
    "print('Номер', '\\t', 'Имя', '\\t\\t', 'Количество подписчиков')\n",
    "for pair in sorteduserlist:\n",
    "    print(n, '\\t', pair[0], '\\t\\t', pair[1])\n",
    "    n += 1\n",
    "    if n == 11:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вопрос 8: * Топ-10 источников твита (из какого приложения написан) (подсказка: для обработки используйте регулярные выражения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываю файл и читаю его сплошным текстом. Делаю кривую регулярку и еще более кривые попытки достать из получившегося источники, вывожу результаты. (Это ужасно, но вроде работает(()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер \t Источник \t Количество употреблений\n",
      "1 \t Twitter for iPhone \t\t 1422\n",
      "2 \t Twitter for Android \t\t 1007\n",
      "3 \t Twitter Web Client \t\t 343\n",
      "4 \t twittbot.net \t\t 123\n",
      "5 \t Twitter Lite \t\t 67\n",
      "6 \t TweetDeck \t\t 54\n",
      "7 \t Twitter for iPad \t\t 38\n",
      "8 \t Hootsuite Inc. \t\t 20\n",
      "9 \t IFTTT \t\t 20\n",
      "10 \t Buffer \t\t 19\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('hw_3_twitter.json', 'r', encoding='utf-8') as twits:\n",
    "    twits = twits.read()\n",
    "sources = re.findall('\"nofollow(.+?)u003e\"', twits)\n",
    "s = []\n",
    "for i in sources:\n",
    "    i = i.split('\\\\')\n",
    "    i = i[2]\n",
    "    i = i[5:]\n",
    "    if i != '':\n",
    "        s.append(i)\n",
    "s = Counter(s).most_common(10)\n",
    "n = 1\n",
    "print('Номер', '\\t', 'Источник', '\\t', 'Количество употреблений')\n",
    "for source in s:\n",
    "    print(n, '\\t', source[0], '\\t\\t', source[1])\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
